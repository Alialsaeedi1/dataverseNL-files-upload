{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48df26a2-5b9d-450c-81d1-7964fe145224",
   "metadata": {},
   "source": [
    "## Uploading Files via DataverseNL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea653cc-3dc8-41d1-96c2-3eecb218cd51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d13ac69-c85a-4641-b422-6691be42d159",
   "metadata": {},
   "outputs": [],
   "source": [
    "The following notebook is intended to wlk you throuth "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eef591-f737-4a6e-be76-eb49407f9be4",
   "metadata": {},
   "source": [
    "https://pydataverse.readthedocs.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fe36000-ec4c-49c2-8ef3-c93a91fab4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U pyDataverse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09184697-55a1-4087-ac75-fc167fc65e5b",
   "metadata": {},
   "source": [
    "Connecting to Native API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51f5d2b5-9db5-4e0d-ae40-a9259292cb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDataverse.api import NativeApi\n",
    "\n",
    "BASE_URL = 'https://dataverse.nl'\n",
    "API_TOKEN = 'b849fb34-9e03-45a7-8f9b-7d722bc26d16'\n",
    "\n",
    "api = NativeApi(BASE_URL, API_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c468e3-290e-49b1-8d9c-f053761b9717",
   "metadata": {},
   "source": [
    "checking the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a37dd40-f003-493a-83b6-aefdd0cb17b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 {'status': 'OK', 'data': {'version': '5.6', 'build': 'dans-develop-68e6bbd70'}}\n"
     ]
    }
   ],
   "source": [
    "resp = api.get_info_version()\n",
    "print(resp.status_code, resp.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06bfdc0-f351-4eac-9aa3-d90b736bf0cc",
   "metadata": {},
   "source": [
    "### Create a Dataverse collection\n",
    "(we skip that for now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6921928-5396-40af-b6e5-05ef49025c9f",
   "metadata": {},
   "source": [
    "## Create a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "310ad123-6565-4a37-9ed5-a99e16d65d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an dempty dataverse object \n",
    "from pyDataverse.models import Dataset\n",
    "ds = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58126e4b-3e1e-4605-b0fa-bfcdf210295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDataverse.utils import read_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d351220c-54b2-4d4f-9bc6-275edce73536",
   "metadata": {},
   "source": [
    "Example from https://github.com/gdcc/pyDataverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2634270-554b-4b8f-ae7b-3cfac9de779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_filename = \"dataset.json\"\n",
    "ds.from_json(read_file(ds_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c5290ab-08a4-447d-ad89-b297a2728501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'citation_displayName': 'Citation Metadata',\n",
       " 'title': 'Youth in Austria 2005',\n",
       " 'author': [{'authorName': 'LastAuthor1, FirstAuthor1',\n",
       "   'authorAffiliation': 'AuthorAffiliation1'}],\n",
       " 'datasetContact': [{'datasetContactEmail': 'ContactEmail1@mailinator.com',\n",
       "   'datasetContactName': 'LastContact1, FirstContact1'}],\n",
       " 'dsDescription': [{'dsDescriptionValue': 'DescriptionText'}],\n",
       " 'subject': ['Medicine, Health and Life Sciences']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is metadata\n",
    "ds.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "471db14e-d399-4a06-851f-004bc55e37f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validates the queality of the metadata\n",
    "ds.validate_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f3f5bf9-f4e7-41b3-91f3-d00c93cd1375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Youth in Austria 2005'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# updating an entry of the metadata\n",
    "ds.get()[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffb85ea9-e3e4-4ece-be4f-c4f34c2875a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Youth in the Netherlands 2005'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.set({\"title\": \"Youth in the Netherlands 2005\"})\n",
    "ds.get()[\"title\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fc7a63-f849-4a57-85ce-5b0443c2abb7",
   "metadata": {},
   "source": [
    "https://dataverse.nl/dataverse/IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2b2cef7-eade-44b0-bf03-8cf762d4307d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with pid 'doi:10.34894/7RAGMX' created.\n"
     ]
    }
   ],
   "source": [
    "resp = api.create_dataset(\"IDS\", ds.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7423b6c0-2250-444a-a868-0e9569884e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'OK', 'data': {'id': 201008, 'persistentId': 'doi:10.34894/7RAGMX'}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52b64777-87bb-4d80-adde-7e12eef00365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doi:10.34894/7RAGMX'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_pid = resp.json()[\"data\"][\"persistentId\"]\n",
    "ds_pid = 'doi:10.34894/7RAGMX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c07d105-ce84-4b52-a8d1-7ccf0f5a5a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doi:10.34894/7RAGMX'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_pid = 'doi:10.34894/7RAGMX'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2ce50a-f588-4922-924f-94615670e876",
   "metadata": {},
   "source": [
    "## Upload a Datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "701716ac-1fec-4bd0-b14b-06b2e5e6ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDataverse.models import Datafile\n",
    "df = Datafile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147c7740-e408-4acf-ac0f-9b8dcbc7a5aa",
   "metadata": {},
   "source": [
    "import your metadata with from_json(). Then, set your PID and filename manually (set()), as they are required as metadata for the upload and are created during the import process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b6798a6-5a91-40b8-8109-4279c8400ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyDataverse.models.Datafile at 0x7ff6a9d6dfa0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab75336b-8fc5-401a-8982-037b3e752596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pid': 'doi:10.34894/7RAGMX', 'filename': 'datafile.txt'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the file is living in this same directory\n",
    "df_filename = \"datafile.txt\"\n",
    "# define dataframe (datafile) properties\n",
    "df.set({\"pid\": ds_pid, \"filename\": df_filename})\n",
    "\n",
    "# visualize\n",
    "df.get()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c9751ae-af54-4704-b6b9-9aad0f204e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'OK', 'data': {'files': [{'description': '', 'label': 'datafile.txt', 'restricted': False, 'version': 1, 'datasetVersionId': 10573, 'dataFile': {'id': 201015, 'persistentId': '', 'pidURL': '', 'filename': 'datafile.txt', 'contentType': 'text/plain', 'filesize': 7, 'description': '', 'storageIdentifier': 'file://17d96570db5-0a44146c7d33', 'rootDataFileId': -1, 'md5': '8b8db3dfa426f6bdb1798d578f5239ae', 'checksum': {'type': 'MD5', 'value': '8b8db3dfa426f6bdb1798d578f5239ae'}, 'creationDate': '2021-12-07'}}]}}\n"
     ]
    }
   ],
   "source": [
    "# id, data, metadata\n",
    "resp = api.upload_datafile(ds_pid, df_filename, df.json())\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24dc9b47-329b-4966-b5bb-add7914f9600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload_datafile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_pid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Add file to a dataset.\n",
       "\n",
       "Add a file to an existing Dataset. Description and tags are optional:\n",
       "\n",
       "HTTP Request:\n",
       "\n",
       ".. code-block:: bash\n",
       "\n",
       "    POST http://$SERVER/api/datasets/$id/add\n",
       "\n",
       "The upload endpoint checks the content of the file, compares it with\n",
       "existing files and tells if already in the database (most likely via\n",
       "hashing).\n",
       "\n",
       "`adding-files <http://guides.dataverse.org/en/latest/api/native-api.html#adding-files>`_.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "identifier : str\n",
       "    Identifier of the dataset.\n",
       "filename : str\n",
       "    Full filename with path.\n",
       "json_str : str\n",
       "    Metadata as JSON string.\n",
       "is_pid : bool\n",
       "    ``True`` to use persistent identifier. ``False``, if not.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "dict\n",
       "    The json string responded by the CURL request, converted to a\n",
       "    dict().\n",
       "\u001b[0;31mFile:\u001b[0m      ~/opt/anaconda3/lib/python3.8/site-packages/pyDataverse/api.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "api.upload_datafile?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615617a4-dd29-46ab-a4d5-d03676f53b3b",
   "metadata": {},
   "source": [
    "By uploading the Datafile, the attached Dataset gets an update. This means that a new unpublished Dataset version is created as a draft and the change is not yet publicly available. To make it available through creating a new Dataset version, publish the Dataset with publish_dataset(). Again, set the release_type=\"major\" to create version 2.0, as a file change always leads to a major version change:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83554bb3-e3d1-4b23-b82b-65a7d9fb6991",
   "metadata": {},
   "source": [
    "### This one definitely publishes the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2fc4ace-dfde-43ea-ba60-67312d94b98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset doi:10.34894/7RAGMX published\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "resp = api.publish_dataset(ds_pid, release_type=\"major\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a16c58-ec15-41a7-bb64-694fdfa2ebda",
   "metadata": {},
   "source": [
    "## Download and save a dataset to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed42498-237f-461d-ba77-6e5ac150af4f",
   "metadata": {},
   "source": [
    "#### IMPORTANT\n",
    "Note that if the dataset is public, you don’t need to have an API_TOKEN. Furthermore, you don’t even need to have a Dataverse account to use this functionality. The code would therefore look as follows:\n",
    "\n",
    "However, you need to know the DOI of the dataset that you want to download. In this example, we use doi:10.34894/LRBQF5 (Lea data), which is hosted on Dataverse NL instance that we specified as base_url. The code looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63f44336-fcb2-4601-abb4-f82bf472489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDataverse.api import NativeApi, DataAccessApi\n",
    "from pyDataverse.models import Dataverse\n",
    "\n",
    "BASE_URL = 'https://dataverse.nl'\n",
    "\n",
    "api = NativeApi(BASE_URL)\n",
    "data_api = DataAccessApi(BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14ec915c-069a-4603-8f08-585d9ed9776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOI = \"doi:10.34894/LRBQF5\"\n",
    "dataset = api.get_dataset(DOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99491572-2b44-482a-bacc-4291248b9f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name All_wow_aggregated_illustrations.csv, id 47243\n",
      "File name get_bhl_images_resize.py, id 47245\n",
      "File name search_aggregate_03.py, id 47244\n"
     ]
    }
   ],
   "source": [
    "files_list = dataset.json()['data']['latestVersion']['files']\n",
    "\n",
    "for file in files_list:\n",
    "    filename = file[\"dataFile\"][\"filename\"] #because we want o name the file exactly how it is in dataverse\n",
    "    file_id = file[\"dataFile\"][\"id\"]\n",
    "    print(\"File name {}, id {}\".format(filename, file_id))\n",
    "    # Here we are getting the data\n",
    "    response = data_api.get_datafile(file_id)\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7752be83-d3d4-4ee1-abfb-de66e1804469",
   "metadata": {},
   "source": [
    "This is wow we save data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81dcf2a-58cc-4d90-b643-6c6c719a3cb9",
   "metadata": {},
   "source": [
    "## Retrieve data as Dataverse tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cda1cc26-58a0-47af-9141-48a5ba8aa3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset_id': 8586,\n",
       "  'pid': 'doi:10.34894/DR3I2A',\n",
       "  'type': 'dataset',\n",
       "  'children': []},\n",
       " {'dataset_id': 36716,\n",
       "  'pid': 'doi:10.34894/LRBQF5',\n",
       "  'type': 'dataset',\n",
       "  'children': [{'datafile_id': 47243,\n",
       "    'filename': 'All_wow_aggregated_illustrations.csv',\n",
       "    'label': 'All_wow_aggregated_illustrations.csv',\n",
       "    'pid': '',\n",
       "    'type': 'datafile'},\n",
       "   {'datafile_id': 47245,\n",
       "    'filename': 'get_bhl_images_resize.py',\n",
       "    'label': 'get_bhl_images_resize.py',\n",
       "    'pid': '',\n",
       "    'type': 'datafile'},\n",
       "   {'datafile_id': 47244,\n",
       "    'filename': 'search_aggregate_03.py',\n",
       "    'label': 'search_aggregate_03.py',\n",
       "    'pid': '',\n",
       "    'type': 'datafile'}]}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fasos example (put the dataverse)\n",
    "tree = api.get_children(\"MUSTS\", children_types= [\"datasets\", \"datafiles\"])\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7a38387-3318-4ddc-b23c-eb5952d7825c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset_id': 201008,\n",
       "  'pid': 'doi:10.34894/7RAGMX',\n",
       "  'type': 'dataset',\n",
       "  'children': [{'datafile_id': 201015,\n",
       "    'filename': 'datafile.txt',\n",
       "    'label': 'datafile.txt',\n",
       "    'pid': '',\n",
       "    'type': 'datafile'}]}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = api.get_children(\"IDS\", children_types= [\"datasets\", \"datafiles\"])\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3938663-08ed-4c26-a8c3-82734e13c871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = api.get_children(\"maastricht\", children_types= [\"datasets\", \"datafiles\"])\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a118897b-6a33-4081-9eda-fad8e4fc0196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m':root'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparent_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dataverse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mchildren_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Walk through children of parent element in Dataverse tree.\n",
       "\n",
       "Default: gets all child dataverses if parent = dataverse or all\n",
       "\n",
       "Example Dataverse Tree:\n",
       "\n",
       ".. code-block:: bash\n",
       "\n",
       "    data = {\n",
       "        'type': 'dataverse',\n",
       "        'dataverse_id': 1,\n",
       "        'dataverse_alias': ':root',\n",
       "        'children': [\n",
       "            {\n",
       "                'type': 'datasets',\n",
       "                'dataset_id': 231,\n",
       "                'pid': 'doi:10.11587/LYFDYC',\n",
       "                'children': [\n",
       "                    {\n",
       "                        'type': 'datafile'\n",
       "                        'datafile_id': 532,\n",
       "                        'pid': 'doi:10.11587/LYFDYC/C2WTRN',\n",
       "                        'filename': '10082_curation.pdf '\n",
       "                    }\n",
       "                ]\n",
       "            }\n",
       "        ]\n",
       "    }\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "parent : str\n",
       "    Description of parameter `parent`.\n",
       "parent_type : str\n",
       "    Description of parameter `parent_type`.\n",
       "children_types : list\n",
       "    Types of children to be collected. 'dataverses', 'datasets' and 'datafiles' are valid list items.\n",
       "auth : bool\n",
       "    Authentication needed\n",
       "\n",
       "Returns\n",
       "-------\n",
       "list\n",
       "    List of Dataverse data type dictionaries. Different ones for\n",
       "    Dataverses, Datasets and Datafiles.\n",
       "\n",
       "# TODO\n",
       "- differentiate between published and unpublished data types\n",
       "- util function to read out all dataverses into a list\n",
       "- util function to read out all datasets into a list\n",
       "- util function to read out all datafiles into a list\n",
       "- Unify tree and models\n",
       "\u001b[0;31mFile:\u001b[0m      ~/opt/anaconda3/lib/python3.8/site-packages/pyDataverse/api.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "api.get_children?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01303f27-1ff2-40cf-9558-20f74b596c0b",
   "metadata": {},
   "source": [
    "## Clean up and remove all created data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c128d05c-74ab-46a9-a1cc-0ff12d0c47d3",
   "metadata": {},
   "source": [
    "ds_piddoi:10.34894/7RAGMX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea1e6e2d-27b0-4297-b6aa-219fcbf70d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doi:10.34894/7RAGMX'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d3cc780-27ae-45d5-9c2a-c9951e092f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = api.destroy_dataset(ds_pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1aeab53d-fce3-42f3-8de3-9f17d1656f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.get_dataset(ds_pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16517257-b12b-4ef6-94d3-00a993b36412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
